---
- hosts: control_plane
  become: true
  name: Setup kube-vip floating ip

  tasks:
    - name: Ensure jq and curl are installed
      ansible.builtin.package:
        name: "{{ item }}"
        state: present
      loop:
        - jq
        - curl

    - name: Create kube-vip alias for containerd
      ansible.builtin.shell: |
        alias kube-vip="ctr image pull ghcr.io/kube-vip/kube-vip:{{ lookup('ansible.builtin.env', 'KUBE_VIP_VERSION') }}; ctr run --rm --net-host ghcr.io/kube-vip/kube-vip:{{ lookup('ansible.builtin.env', 'KUBE_VIP_VERSION') }} vip /kube-vip"

    - name: Ensure /etc/kubernetes/manifests directory exists
      ansible.builtin.file:
        path: /etc/kubernetes/manifests
        state: directory
        owner: root
        group: root
        mode: '0755'

    - name: Debug KUBE_VIP_INTERFACE and KUBE_VIP_IP
      ansible.builtin.debug:
        msg:
          - "KUBE_VIP_INTERFACE: {{ lookup('ansible.builtin.env', 'KUBE_VIP_INTERFACE') }}"
          - "KUBE_VIP_IP: {{ lookup('ansible.builtin.env', 'KUBE_VIP_IP') }}"

    - name: Set kube-vip environment variables
      ansible.builtin.set_fact:
        kube_vip_interface: "{{ lookup('ansible.builtin.env', 'KUBE_VIP_INTERFACE') }}"
        kube_vip_ip: "{{ lookup('ansible.builtin.env', 'KUBE_VIP_IP') }}"

    - name: Generate kube-vip static pod manifest for control plane with ARP
      ansible.builtin.shell: |
        kube-vip manifest pod \
        --interface {{ kube_vip_interface }} \
        --address {{ kube_vip_ip }} \
        --controlplane \
        --arp \
        --leaderElection | tee /etc/kubernetes/manifests/kube-vip.yaml
      args:
        executable: /bin/bash
      register: manifest_output

    - name: Display kube-vip manifest creation output
      debug:
        var: manifest_output.stdout

    - name: Copy kube-vip manifest to all control plane nodes
      copy:
        src: /etc/kubernetes/manifests/kube-vip.yaml
        dest: /etc/kubernetes/manifests/kube-vip.yaml
        mode: '0644'
        owner: root
        group: root
      when: inventory_hostname != groups['control_plane'][0]

- hosts: control_plane
  become: true

  tasks:
    - name: Pulling images required for setting up a Kubernetes cluster
      shell: kubeadm config images pull

    - name: Download runc binary
      ansible.builtin.get_url:
        url: https://github.com/opencontainers/runc/releases/download/{{ lookup('ansible.builtin.env', 'RUNC_VERSION') }}/runc.amd64
        dest: /tmp/runc.amd64
        mode: '0755'

    - name: Install runc binary
      ansible.builtin.command:
        cmd: install -m 755 /tmp/runc.amd64 /usr/local/sbin/runc

    - name: Run kubeadm init with control plane endpoint
      shell: |
        kubeadm init \
        --apiserver-advertise-address={{ hostvars[inventory_hostname]['ansible_host'] }} \
        --apiserver-cert-extra-sans={{ lookup('ansible.builtin.env', 'TAILSCALE_JUMP_SERVER_VPN_IP') }} \
        --pod-network-cidr={{ lookup('ansible.builtin.env', 'POD_NETWORK_CIDR') }} \
        --control-plane-endpoint={{ lookup('ansible.builtin.env', 'KUBE_VIP_IP') }} \
        --v=5
      args:
        executable: /bin/bash
      register: myshell_output

    - debug: msg="{{ myshell_output.stdout }}"

    - name: Create .kube directory
      become: true
      become_user: admin
      file:
        path: $HOME/.kube
        state: directory
        mode: 0755

    - name: Copy admin.conf to user's kube config
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/admin/.kube/config
        remote_src: yes
        owner: admin

- hosts: control_plane
  tasks:

    - name: Check if Kubernetes cluster is running
      command: kubectl cluster-info
      register: cluster_info
      ignore_errors: true

    - name: Print cluster status
      debug:
        var: cluster_info

    - name: Create Calico Operator using kubectl
      shell: kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/{{ lookup('ansible.builtin.env', 'CALICO_VERSION') }}/manifests/tigera-operator.yaml --validate=false
      register: tigera_operator_output

    - name: Download Calico Custom Resources manifest
      ansible.builtin.get_url:
        url: https://raw.githubusercontent.com/projectcalico/calico/{{ lookup('ansible.builtin.env', 'CALICO_VERSION') }}/manifests/custom-resources.yaml
        dest: /tmp/custom-resources.yaml

    - name: Change cidr value in the custom-resources.yaml
      ansible.builtin.replace:
        path: /tmp/custom-resources.yaml
        regexp: 'cidr: 192\.168\.0\.0/16'
        replace: "cidr: {{ lookup('ansible.builtin.env', 'POD_NETWORK_CIDR') }}"

    - name: Apply Custom Resources manifest using kubectl
      shell: kubectl apply -f /tmp/custom-resources.yaml
      register: calico_custom_resources_output

    - name: Ensure Tigera Operator was created successfully
      debug:
        msg: "{{ tigera_operator_output.stdout }}"

    - name: Ensure Calico Custom Resources applied successfully
      debug:
        msg: "{{ calico_custom_resources_output.stdout }}"
